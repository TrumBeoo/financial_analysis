"""
Enhanced Callbacks cho Dashboard v·ªõi t·∫•t c·∫£ t√≠nh nƒÉng m·ªõi
"""
from dash import Output, Input, State, html, callback_context
import dash_bootstrap_components as dbc
from dash.exceptions import PreventUpdate
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime, timedelta
import logging
import numpy as np

from src.database.db_manager import DatabaseManager
from src.utils.performance import cache_result, optimize_dataframe, dashboard_cache
from config.settings import SECTOR_MAPPINGS, PERFORMANCE_CONFIG
from src.crawler.url_parser import URLParser
from src.processing.text_preprocessor import VietnameseTextPreprocessor
from src.processing.sentiment_analyzer import SentimentAnalyzer
from config.settings import SENTIMENT_COLORS, SENTIMENT_LABELS

logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o
db_manager = DatabaseManager()
url_parser = URLParser()
preprocessor = VietnameseTextPreprocessor()
sentiment_analyzer = SentimentAnalyzer()

def register_enhanced_callbacks(app):
    """ƒêƒÉng k√Ω t·∫•t c·∫£ callbacks n√¢ng cao"""
    
    # Stats v·ªõi filters
    @app.callback(
        [Output('total-articles', 'children'),
         Output('positive-count', 'children'),
         Output('neutral-count', 'children'),
         Output('negative-count', 'children'),
         Output('market-sentiment-index', 'children')],
        [Input('interval-component', 'n_intervals'),
         Input('sector-filter', 'value'),
         Input('time-filter', 'value'),
         Input('sentiment-filter', 'value')]
    )
    def update_stats_with_filters(n, sector, days, sentiment_type):
        """C·∫≠p nh·∫≠t th·ªëng k√™ v·ªõi filters"""
        df = get_filtered_data(sector, days, sentiment_type)
        
        if df.empty:
            return "0", "0", "0", "0", "+0.00"
        
        total = len(df)
        positive = len(df[df['predicted_label'] == 2]) if 'predicted_label' in df.columns else 0
        neutral = len(df[df['predicted_label'] == 1]) if 'predicted_label' in df.columns else 0
        negative = len(df[df['predicted_label'] == 0]) if 'predicted_label' in df.columns else 0
        
        # Market Sentiment Index
        if 'predicted_label' in df.columns:
            sentiment_scores = df['predicted_label'].map({0: -1, 1: 0, 2: 1})
            avg_score = sentiment_scores.mean()
            market_index = f"{avg_score:+.2f}"
        else:
            market_index = "+0.00"
        
        return str(total), str(positive), str(neutral), str(negative), market_index
    
    # Gauge Chart cho Market Sentiment
    @app.callback(
        Output('sentiment-gauge-chart', 'figure'),
        [Input('interval-component', 'n_intervals'),
         Input('sector-filter', 'value'),
         Input('time-filter', 'value'),
         Input('sentiment-filter', 'value')]
    )
    def update_gauge_chart(n, sector, days, sentiment_type):
        """Bi·ªÉu ƒë·ªì gauge cho sentiment t·ªïng quan"""
        df = get_filtered_data(sector, days, sentiment_type)
        
        if df.empty or 'predicted_label' not in df.columns:
            return go.Figure()
        
        # T√≠nh t·ª∑ l·ªá t√≠ch c·ª±c
        sentiment_counts = df['predicted_label'].value_counts(normalize=True)
        positive_ratio = sentiment_counts.get(2, 0) * 100
        
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = positive_ratio,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "T·ª∑ l·ªá tin t√≠ch c·ª±c (%)"},
            delta = {'reference': 50},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "#2ecc71"},
                'steps': [
                    {'range': [0, 25], 'color': "#ffebee"},
                    {'range': [25, 50], 'color': "#fff3e0"},
                    {'range': [50, 75], 'color': "#e8f5e8"},
                    {'range': [75, 100], 'color': "#c8e6c9"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        fig.update_layout(height=300)
        return fig
    
    # Heatmap theo ng√†nh
    @app.callback(
        Output('sector-heatmap', 'figure'),
        [Input('interval-component', 'n_intervals'),
         Input('time-filter', 'value'),
         Input('sentiment-filter', 'value')]
    )
    def update_heatmap(n, days, sentiment_type):
        """B·∫£n ƒë·ªì nhi·ªát theo ng√†nh"""
        df = get_filtered_data('all', days, sentiment_type)
        
        if df.empty or 'predicted_label' not in df.columns:
            return go.Figure()
        
        # C√°c ng√†nh ch√≠nh
        sectors = ['Banking', 'Energy', 'Real Estate', 'Technology', 'Manufacturing', 'Other']
        sentiment_matrix = []
        
        for sector in sectors:
            if 'sectors' in df.columns:
                sector_data = df[df['sectors'].str.contains(sector, na=False)]
            else:
                sector_data = df
                
            if not sector_data.empty:
                sentiment_scores = sector_data['predicted_label'].map({0: -1, 1: 0, 2: 1})
                avg_score = sentiment_scores.mean()
            else:
                avg_score = 0
            sentiment_matrix.append([avg_score])
        
        fig = go.Figure(data=go.Heatmap(
            z=sentiment_matrix,
            y=sectors,
            x=['Sentiment Score'],
            colorscale='RdYlGn',
            zmid=0,
            colorbar=dict(title="Sentiment Score"),
            text=[[f"{score[0]:.2f}"] for score in sentiment_matrix],
            texttemplate="%{text}",
            textfont={"size": 12}
        ))
        
        fig.update_layout(
            height=300,
            xaxis_title='',
            yaxis_title='',
            margin=dict(l=100, r=50, t=20, b=20)
        )
        
        return fig
    
    # Enhanced Sector Bar Chart
    @app.callback(
        Output('sector-bar-chart', 'figure'),
        [Input('interval-component', 'n_intervals'),
         Input('sector-filter', 'value'),
         Input('time-filter', 'value'),
         Input('sentiment-filter', 'value')]
    )
    def update_sector_chart(n, sector, days, sentiment_type):
        """Bi·ªÉu ƒë·ªì c·ªôt theo ng√†nh v·ªõi ƒëi·ªÉm sentiment"""
        df = get_filtered_data('all', days, sentiment_type)
        
        if df.empty or 'predicted_label' not in df.columns:
            return go.Figure()
        
        # Ensure sectors column
        if 'sectors' not in df.columns:
            df['sectors'] = 'Other'
        
        # Calculate average sentiment score by sector
        df['sentiment_score'] = df['predicted_label'].map({0: -1, 1: 0, 2: 1})
        sector_stats = df.groupby('sectors').agg({
            'sentiment_score': 'mean',
            'predicted_label': 'count'
        }).reset_index()
        
        sector_stats = sector_stats.sort_values('sentiment_score', ascending=False)
        
        # Color based on sentiment
        colors = [SENTIMENT_COLORS['T√≠ch c·ª±c'] if score > 0.1 else 
                 SENTIMENT_COLORS['Ti√™u c·ª±c'] if score < -0.1 else 
                 SENTIMENT_COLORS['Trung t√≠nh'] for score in sector_stats['sentiment_score']]
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=sector_stats['sectors'],
            y=sector_stats['sentiment_score'],
            marker_color=colors,
            text=[f'{score:.2f}<br>({count} b√†i)' for score, count in 
                  zip(sector_stats['sentiment_score'], sector_stats['predicted_label'])],
            textposition='auto',
            hovertemplate='<b>%{x}</b><br>Sentiment: %{y:.2f}<br>S·ªë b√†i: %{customdata}<extra></extra>',
            customdata=sector_stats['predicted_label']
        ))
        
        fig.update_layout(
            xaxis_title='Ng√†nh',
            yaxis_title='ƒêi·ªÉm Sentiment Trung b√¨nh',
            yaxis=dict(range=[-1, 1]),
            hovermode='x unified'
        )
        
        return fig
    
    # Word Cloud Display
    @app.callback(
        Output('word-cloud-display', 'children'),
        [Input('interval-component', 'n_intervals'),
         Input('sector-filter', 'value'),
         Input('time-filter', 'value')]
    )
    def update_word_cloud(n, sector, days):
        """Hi·ªÉn th·ªã t·ª´ kh√≥a n·ªïi b·∫≠t"""
        df = get_filtered_data(sector, days, 'all')
        
        if df.empty or 'cleaned_text' not in df.columns:
            return html.P("Ch∆∞a c√≥ d·ªØ li·ªáu", className='text-muted text-center')
        
        # Extract keywords
        all_text = ' '.join(df['cleaned_text'].dropna())
        keywords = extract_keywords(all_text, top_n=15)
        
        if not keywords:
            return html.P("Ch∆∞a c√≥ t·ª´ kh√≥a", className='text-muted text-center')
        
        # Create badges with different sizes
        badges = []
        for i, (word, count) in enumerate(keywords):
            size = 'lg' if i < 3 else 'md' if i < 8 else 'sm'
            color = 'primary' if i < 3 else 'info' if i < 8 else 'secondary'
            
            badges.append(
                dbc.Badge(
                    f"{word} ({count})",
                    color=color,
                    className=f'me-1 mb-1 badge-{size}',
                    style={'fontSize': '14px' if size == 'lg' else '12px' if size == 'md' else '10px'}
                )
            )
        
        return html.Div(badges)
    
    # Enhanced Timeline
    @app.callback(
        Output('sentiment-timeline', 'figure'),
        [Input('interval-component', 'n_intervals'),
         Input('sector-filter', 'value'),
         Input('time-filter', 'value'),
         Input('sentiment-filter', 'value')]
    )
    def update_timeline(n, sector, days, sentiment_type):
        """Timeline v·ªõi smooth line v√† trend"""
        df = get_filtered_data(sector, days, sentiment_type)
        
        if df.empty or 'crawl_time' not in df.columns:
            return go.Figure()
        
        # Prepare data
        if 'predicted_sentiment' not in df.columns and 'predicted_label' in df.columns:
            df['predicted_sentiment'] = df['predicted_label'].map({0: 'Ti√™u c·ª±c', 1: 'Trung t√≠nh', 2: 'T√≠ch c·ª±c'})
        
        df['date'] = pd.to_datetime(df['crawl_time']).dt.date
        
        # Group by date and sentiment
        timeline_data = df.groupby(['date', 'predicted_sentiment']).size().reset_index(name='count')
        
        fig = go.Figure()
        
        for sentiment in ['T√≠ch c·ª±c', 'Trung t√≠nh', 'Ti√™u c·ª±c']:
            sentiment_data = timeline_data[timeline_data['predicted_sentiment'] == sentiment]
            if not sentiment_data.empty:
                fig.add_trace(go.Scatter(
                    x=sentiment_data['date'],
                    y=sentiment_data['count'],
                    mode='lines+markers',
                    name=sentiment,
                    line=dict(color=SENTIMENT_COLORS[sentiment], width=3),
                    marker=dict(size=6),
                    hovertemplate=f'<b>{sentiment}</b><br>Ng√†y: %{{x}}<br>S·ªë b√†i: %{{y}}<extra></extra>'
                ))
        
        fig.update_layout(
            xaxis_title='Ng√†y',
            yaxis_title='S·ªë l∆∞·ª£ng b√†i vi·∫øt',
            hovermode='x unified',
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        
        return fig
    
    # Correlation Chart (Mock data for now)
    @app.callback(
        Output('correlation-chart', 'figure'),
        Input('interval-component', 'n_intervals')
    )
    def update_correlation(n):
        """Bi·ªÉu ƒë·ªì t∆∞∆°ng quan sentiment-gi√° (mock data)"""
        # Generate mock correlation data
        dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
        sentiment_scores = np.random.normal(0, 0.3, 30)
        price_changes = sentiment_scores * 0.6 + np.random.normal(0, 0.15, 30)
        
        fig = go.Figure()
        
        # Sentiment line
        fig.add_trace(go.Scatter(
            x=dates,
            y=sentiment_scores,
            mode='lines',
            name='Sentiment Score',
            line=dict(color='#3498db', width=2),
            yaxis='y'
        ))
        
        # Price change line
        fig.add_trace(go.Scatter(
            x=dates,
            y=price_changes,
            mode='lines',
            name='Price Change (%)',
            line=dict(color='#e74c3c', width=2),
            yaxis='y2'
        ))
        
        fig.update_layout(
            yaxis=dict(title='Sentiment Score', side='left', color='#3498db'),
            yaxis2=dict(title='Price Change (%)', side='right', overlaying='y', color='#e74c3c'),
            hovermode='x unified',
            height=300,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        
        return fig
    
    # Enhanced News Table
    @app.callback(
        Output('enhanced-news-table', 'children'),
        [Input('interval-component', 'n_intervals'),
         Input('sector-filter', 'value'),
         Input('time-filter', 'value'),
         Input('sentiment-filter', 'value')]
    )
    def update_enhanced_table(n, sector, days, sentiment_type):
        """B·∫£ng tin t·ª©c n√¢ng cao v·ªõi t∆∞∆°ng t√°c"""
        df = get_filtered_data(sector, days, sentiment_type, limit=20)
        
        if df.empty:
            return html.P("Ch∆∞a c√≥ d·ªØ li·ªáu", className='text-muted text-center')
        
        # Ensure sentiment column
        if 'predicted_sentiment' not in df.columns and 'predicted_label' in df.columns:
            df['predicted_sentiment'] = df['predicted_label'].map({0: 'Ti√™u c·ª±c', 1: 'Trung t√≠nh', 2: 'T√≠ch c·ª±c'})
        
        rows = []
        for idx, row in df.iterrows():
            sentiment = row.get('predicted_sentiment', 'N/A')
            color_map = {'T√≠ch c·ª±c': 'success', 'Trung t√≠nh': 'secondary', 'Ti√™u c·ª±c': 'danger'}
            color = color_map.get(sentiment, 'secondary')
            
            # Format title with highlighting
            title = row.get('title', 'N/A')
            truncated_title = title[:80] + '...' if len(title) > 80 else title
            highlighted_title = highlight_sentiment_words(truncated_title)
            
            # Format time
            crawl_time = row.get('crawl_time', datetime.now())
            if hasattr(crawl_time, 'strftime'):
                time_str = crawl_time.strftime('%d/%m %H:%M')
            else:
                time_str = 'N/A'
            
            rows.append(
                html.Tr([
                    html.Td([
                        html.Div([
                            html.Strong(highlighted_title),
                            html.Br(),
                            html.Small(str(row.get('content', ''))[:100] + '...', className='text-muted')
                        ])
                    ]),
                    html.Td(row.get('source', 'N/A')),
                    html.Td([
                        dbc.Badge(sentiment, color=color, className='me-1'),
                        html.Br(),
                        html.Small(f"Score: {row.get('sentiment_positive', 0):.2f}", className='text-muted')
                    ]),
                    html.Td(row.get('sectors', 'Other')),
                    html.Td(time_str)
                ])
            )
        
        table = dbc.Table([
            html.Thead(
                html.Tr([
                    html.Th("Ti√™u ƒë·ªÅ & N·ªôi dung"),
                    html.Th("Ngu·ªìn"),
                    html.Th("Sentiment"),
                    html.Th("Ng√†nh"),
                    html.Th("Th·ªùi gian")
                ])
            ),
            html.Tbody(rows)
        ], bordered=True, hover=True, responsive=True, striped=True)
        
        return table
    
    # Enhanced URL Analysis
    @app.callback(
        [Output('url-analysis-result', 'children'),
         Output('detailed-url-analysis', 'children')],
        Input('analyze-btn', 'n_clicks'),
        State('url-input', 'value'),
        prevent_initial_call=True
    )
    def analyze_url_enhanced(n_clicks, url):
        """Ph√¢n t√≠ch URL chi ti·∫øt v·ªõi keyword highlighting"""
        if not url:
            alert = dbc.Alert("Vui l√≤ng nh·∫≠p URL", color='warning')
            return alert, alert
        
        try:
            # Parse URL
            result = url_parser.parse_url(url)
            
            if not result['success']:
                error_alert = dbc.Alert(f"L·ªói: {result.get('error', 'Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung')}", color='danger')
                return error_alert, error_alert
            
            # Preprocess
            full_text = f"{result['title']} {result['content']}"
            processed = preprocessor.preprocess_pipeline(full_text)
            
            # Analyze sentiment
            sentiment = sentiment_analyzer.analyze(full_text)
            sentiment_label = SENTIMENT_LABELS[sentiment['label']]
            
            # Extract keywords
            keywords = extract_keywords(processed['cleaned_text'])
            
            # Save to database
            save_data = {
                'source': result['source'],
                'title': result['title'],
                'content': result['content'][:500],
                'link': url,
                'crawl_time': datetime.now(),
                'cleaned_text': processed['cleaned_text'],
                'sentiment_positive': sentiment['positive'],
                'sentiment_negative': sentiment['negative'],
                'sentiment_neutral': sentiment['neutral'],
                'predicted_label': sentiment['label'],
                'predicted_sentiment': sentiment_label,
                'sectors': 'Other'
            }
            
            df_save = pd.DataFrame([save_data])
            db_manager.save_processed_data(df_save)
            
            # Basic result
            basic_result = dbc.Alert(f"‚úÖ Ph√¢n t√≠ch th√†nh c√¥ng! Sentiment: {sentiment_label}", color='success')
            
            # Detailed result
            sentiment_color_map = {'T√≠ch c·ª±c': 'success', 'Trung t√≠nh': 'secondary', 'Ti√™u c·ª±c': 'danger'}
            color = sentiment_color_map.get(sentiment_label, 'secondary')
            
            detailed_result = dbc.Card([
                dbc.CardHeader([
                    html.H4("üîç Ph√¢n t√≠ch chi ti·∫øt b√†i vi·∫øt", className="mb-0")
                ]),
                dbc.CardBody([
                    dbc.Row([
                        dbc.Col([
                            html.H5("üì∞ Th√¥ng tin b√†i vi·∫øt"),
                            html.P([html.Strong("Ti√™u ƒë·ªÅ: "), result['title']]),
                            html.P([html.Strong("Ngu·ªìn: "), result['source']]),
                            html.P([html.Strong("Ng√†y: "), datetime.now().strftime('%d/%m/%Y %H:%M')]),
                            html.Hr(),
                            html.H5("üìä Ph√¢n t√≠ch Sentiment"),
                            dbc.Badge(sentiment_label, color=color, className='fs-6 mb-3'),
                            html.Div([
                                html.P(f"T√≠ch c·ª±c: {sentiment['positive']:.2f}", className='mb-1'),
                                dbc.Progress(value=sentiment['positive']*100, color='success', className='mb-2'),
                                html.P(f"Trung t√≠nh: {sentiment['neutral']:.2f}", className='mb-1'),
                                dbc.Progress(value=sentiment['neutral']*100, color='secondary', className='mb-2'),
                                html.P(f"Ti√™u c·ª±c: {sentiment['negative']:.2f}", className='mb-1'),
                                dbc.Progress(value=sentiment['negative']*100, color='danger')
                            ], className='mb-3')
                        ], width=6),
                        dbc.Col([
                            html.H5("üìù T√≥m t·∫Øt n·ªôi dung"),
                            html.P(result['content'][:400] + '...' if len(result['content']) > 400 else result['content']),
                            html.Hr(),
                            html.H5("üîë T·ª´ kh√≥a quan tr·ªçng"),
                            html.Div([
                                dbc.Badge(keyword[0], color='info', className='me-1 mb-1') 
                                for keyword in keywords[:10]
                            ]),
                            html.Hr(),
                            html.H5("üîó Li√™n k·∫øt"),
                            html.A("Xem b√†i g·ªëc", href=url, target="_blank", className="btn btn-outline-primary")
                        ], width=6)
                    ])
                ])
            ], className='mt-3')
            
            return basic_result, detailed_result
            
        except Exception as e:
            logger.error(f"Error in URL analysis: {str(e)}")
            error_alert = dbc.Alert(f"L·ªói x·ª≠ l√Ω: {str(e)}", color='danger')
            return error_alert, error_alert

@cache_result(timeout=PERFORMANCE_CONFIG['cache_timeout'])
def get_filtered_data(sector='all', days=30, sentiment_type='all', limit=1000):
    """L·∫•y d·ªØ li·ªáu ƒë√£ l·ªçc theo c√°c ti√™u ch√≠ v·ªõi cache"""
    # Try cache first
    cache_key = f"filtered_data_{sector}_{days}_{sentiment_type}_{limit}"
    cached_result = dashboard_cache.get(cache_key)
    if cached_result is not None:
        return cached_result
    
    df = db_manager.load_processed_data(limit=limit)
    
    if df.empty:
        return df
    
    # Optimize DataFrame
    df = optimize_dataframe(df)
    
    # Filter by time
    if 'crawl_time' in df.columns:
        cutoff_date = datetime.now() - timedelta(days=days)
        df = df[pd.to_datetime(df['crawl_time']) >= cutoff_date]
    
    # Map sectors to standard names
    if 'sectors' in df.columns:
        df['sectors'] = df['sectors'].map(lambda x: SECTOR_MAPPINGS.get(x, 'Other') if pd.notna(x) else 'Other')
    
    # Filter by sector
    if sector != 'all' and 'sectors' in df.columns:
        df = df[df['sectors'] == sector]
    
    # Filter by sentiment
    if sentiment_type != 'all':
        if 'predicted_sentiment' in df.columns:
            df = df[df['predicted_sentiment'] == sentiment_type]
        elif 'predicted_label' in df.columns:
            label_map = {'T√≠ch c·ª±c': 2, 'Trung t√≠nh': 1, 'Ti√™u c·ª±c': 0}
            if sentiment_type in label_map:
                df = df[df['predicted_label'] == label_map[sentiment_type]]
    
    # Cache result
    dashboard_cache.set(cache_key, df)
    
    return df

def highlight_sentiment_words(text):
    """Highlight t·ª´ c·∫£m x√∫c trong text"""
    from dash import dcc
    
    positive_words = ['tƒÉng', 'm·∫°nh', 't·ªët', 'ph·ª•c h·ªìi', '·ªïn ƒë·ªãnh', 'kh·∫£ quan', 't√≠ch c·ª±c', 'l·ª£i nhu·∫≠n', 'tƒÉng tr∆∞·ªüng']
    negative_words = ['gi·∫£m', 'kh√≥ khƒÉn', 'suy gi·∫£m', 'r·ªßi ro', 'th√°ch th·ª©c', 'ti√™u c·ª±c', 'l·ªó', 's·ª•t gi·∫£m']
    
    highlighted = text
    for word in positive_words:
        if word in highlighted.lower():
            highlighted = highlighted.replace(word, f'<span style="color: #2ecc71; font-weight: bold;">{word}</span>')
    for word in negative_words:
        if word in highlighted.lower():
            highlighted = highlighted.replace(word, f'<span style="color: #e74c3c; font-weight: bold;">{word}</span>')
    
    return dcc.Markdown(highlighted, dangerously_allow_html=True)

def extract_keywords(text, top_n=10):
    """Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng"""
    if not text:
        return []
    
    words = text.split()
    # Filter words longer than 3 characters
    keywords = [word for word in words if len(word) > 3]
    
    # Count frequency
    word_freq = {}
    for word in keywords:
        word_freq[word] = word_freq.get(word, 0) + 1
    
    # Return top keywords with count
    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
    return sorted_words[:top_n]